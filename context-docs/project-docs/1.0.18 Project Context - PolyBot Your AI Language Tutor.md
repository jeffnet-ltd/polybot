Version: 1.0.18 (Stable, Verified, & Tested)

Status: Production Ready - Core Features Complete + Scenario-Based Practice Mode Architecture Designed

Last Updated: 2025-01-XX (Updated with Scenario-Based Practice Mode, Game State Architecture, and Voice/Text Mode Separation)

Dev Environment: HP EliteBook 820 G4 / Windows 11 WSL2 (NVIDIA RTX 2080 Ti - Docker Desktop with GPU Support) $\rightarrow$ **Migrating to RunPod Serverless GPU**

## Executive Summary

Polybot is an **AI-powered multilingual language learning platform** that runs entirely locally $\rightarrow$ **Migrating to a Serverless Cloud Architecture for scalability and global deployment.** It combines a structured **10-module CEFR A1 Curriculum** with free-flowing AI roleplay to provide a "True Bilingual" learning experience.

**Key Differentiator:** Users learn in their target language while receiving explanations in their native language. The architecture ensures total privacy and zero latency through local LLM use, which will be maintained in the cloud via **Serverless GPU Scaling**.

**Current Status:** Module A1.1 (Greetings & Introductions) is fully implemented with 9 lessons (including self-assessment), comprehensive exercise types including new listening, reading, and writing exercises, and a static Boss Fight system. Enhanced feedback mechanisms, voice integration (Whisper STT), and TTS-based listening comprehension are operational. **Scenario-Based Practice Mode architecture is designed and ready for implementation.**

---

## Technical Architecture (V2.0 Target)

### Stack Overview

- **Frontend:** React 18.2.0 + Tailwind CSS + Lucide React
    
    - **Deployment:** **Vercel / Netlify** (Free Tier)
        
- **Backend:** FastAPI (Python 3.11) + **Llama 3 8B Instruct**
    
    - **Deployment:** **RunPod Serverless GPU** (Flex Workers for cost-efficiency)
        
- **Auth:** Google OAuth 2.0 (via `authlib`) + Local Session Management
    
- **Database:** MongoDB 7.0 $\rightarrow$ **MongoDB Atlas (Free Tier)**
    
- **Testing:** `pytest` suite with `AsyncMock` for backend logic verification.
    
- **Infrastructure:** Docker + Docker Compose (V2) - **Migrating to Serverless Endpoints.**

### Voice Integration (Implemented & Planned)

|**Component**|**Status**|**Model**|**Technical Justification**|
|---|---|---|---|
|**Speech-to-Text (STT)**|**‚úÖ Implemented**|**Whisper (OpenAI)**|Integrated for Echo Chamber exercises and Boss Fight voice input. Provides accurate transcription for pronunciation feedback.|
|**Text-to-Speech (TTS)**|**‚úÖ Implemented (Current)**|**Edge-TTS (Microsoft)**|Currently used for audio playback of vocabulary and phrases. Provides high-quality, natural-sounding synthesis.|
|**Text-to-Speech (TTS)**|**üîÑ Planned (V2.0)**|**XTTS-v2 (Coqui)**|Free and open-source solution that provides **high-quality, expressive, multilingual synthesis**. Enables **zero-shot voice cloning** from a 6-second audio clip for a consistent AI Tutor voice across all target languages.|

### Hardware Requirement

- **AI Model:** Llama 3 8B Instruct will be hosted on **RunPod Serverless GPUs** (e.g., A40, L40S, or RTX 4090) using Docker containers.
    
- **Load Management:** **Model Ducking (VRAM Swapping)** and potential **4/8-bit Quantization** will be implemented to efficiently manage the concurrent VRAM load of Llama 3 and the Voice models (Whisper/XTTS-v2) on the shared GPU instance.

---

## Implemented Features (v1.0.18)

### Module A1.1: Greetings & Introductions

**Status:** ‚úÖ Fully Implemented with Enhanced Exercise Types

- **9 Complete Lessons:**
    0. Self-Assessment: Greetings & Introductions (NEW)
    1. The Informal Zone (Friends & Peers)
    2. Formal Greetings & Time-Based Expressions
    3. Introducing Yourself (Pronunciation & Verbs)
    4. Polite Expressions & Closings
    5. Subject Pronouns & The Verb 'To Be'
    6. Introduction to Nouns
    7. Where Are You From? (Countries & Nationalities)
    8. Conversation Practice: Meeting a Neighbor - Informal & Formal (Boss Fight)

- **Grammar Coverage:**
    - Subject Pronouns (Io, Tu, Lui, Lei)
    - Verb "To Be" (Essere) - Present Simple conjugations
    - Nouns - Gender (Masculine/Feminine) and Articles (Un/Una, Il/La)
    - Asking about origin: "Di dove sei?" / "Di dove √®?"
    - Countries and Nationalities: Italia, Francia, Spagna, Stati Uniti, Regno Unito / italiano/a, francese, spagnolo/a, americano/a, inglese

### Exercise Types Implemented

|**Exercise Type**|**Status**|**Features**|
|---|---|---|
|**Info Cards**|‚úÖ Complete|Audio playback (Edge-TTS), vocabulary introduction, grammar explanations, cultural notes support|
|**Match Pairs**|‚úÖ Complete|Audio-to-text matching, Italian-English word pairs, interactive selection, state reset on exercise change, improved click handlers, vocabulary review mode|
|**Unscramble**|‚úÖ Complete|Drag-and-drop sentence construction, word order practice, comma normalization, common mistakes detection with enhanced feedback|
|**Echo Chamber**|‚úÖ Complete|Voice recording (MediaRecorder API), Whisper STT transcription, phonetic scoring (Levenshtein distance), playback before submission|
|**Mini-Prompt**|‚úÖ Complete|Contextual exercises, AI validation with fallback logic, context-specific feedback, accent detection (Italian), "almost" state for partial correctness, extension activities support|
|**Fill Blank**|‚úÖ Complete|Multiple choice fill-in-the-blank exercises|
|**Multiple Choice**|‚úÖ Complete|Standard multiple choice questions|
|**Gender Categorize**|‚úÖ Complete|Drag-and-drop noun gender classification (Maschile/Femminile), visual column layout|
|**Listening Comprehension**|‚úÖ Complete (NEW)|TTS-based audio playback with hidden sentences, multiple choice questions, replay functionality (up to max_plays), auto-play on mount|
|**Reading Comprehension**|‚úÖ Complete (NEW)|Text-based comprehension exercises with highlighted vocabulary, multiple choice questions, context-aware explanations|
|**Free Writing**|‚úÖ Complete (NEW)|Open-ended writing tasks with AI validation, required elements checking, example responses, context-based prompts|
|**Form Fill**|‚úÖ Complete (NEW)|Interactive form completion exercises with multiple field types (text, select), validation rules, hints|
|**Self-Assessment**|‚úÖ Complete (NEW)|Confidence-based assessment questions, skip option, no scoring, custom completion screen|
|**Boss Fight**|‚úÖ Complete|Static 2-round conversation system (Informal/Formal), hints tracking, grammar/spelling feedback, round transition controls|

### Enhanced Feedback System

- **Pedagogically-Focused Messages:** All exercises provide detailed explanations for correct/incorrect answers
- **"Almost" State:** Amber/warning feedback for partially correct answers (e.g., wrong accent, missing polite phrase)
- **Context-Specific Validation:** Mini-Prompt exercises use intelligent validation based on context (greetings, introductions, ordering, etc.)
- **Accent Detection:** Italian exercises detect and provide feedback on accent errors (√® vs √©)
- **Common Mistakes Detection:** Unscramble exercises now include pattern-based common mistakes detection with specific feedback messages
- **Cultural Notes:** Info cards support cultural note mode with enhanced styling and contextual information
- **Vocabulary Review:** Match exercises support review mode for vocabulary recycling
- **Extension Activities:** Optional challenge exercises for advanced learners with skip functionality

### UI/UX Enhancements

- **Accented Letter Chips:** Clickable accented letters (√†, √®, √©, √¨, √≤, √π) for Italian input in text fields
- **Fade Animations:** Smooth transitions between Boss Fight rounds
- **Progress Tracking:** Visual progress bars and score tracking
- **Hints System:** Real-time word/phrase tracking in Boss Fight with dynamic instruction text
- **Custom Completion Screens:** Self-assessment lessons show custom completion message without score display
- **Consistent Navigation:** All lessons use "Continue to Next Lesson" button for consistent user flow
- **TTS Error Handling:** Graceful fallback to TTS when audio files are unavailable, with user-friendly error messages

### Voice Integration (Current)

- **Whisper STT:** Integrated for Echo Chamber and Boss Fight voice input
- **Edge-TTS:** Currently used for all audio playback, vocabulary pronunciation, and listening comprehension exercises
- **TTS-Based Listening:** Listening comprehension exercises use TTS to read hidden sentences (not displayed to user) with replay functionality
- **Audio Recording:** Browser MediaRecorder API with playback controls
- **Pronunciation Feedback:** Phonetic scoring using Levenshtein distance algorithm
- **Error Handling:** Automatic TTS fallback when audio files fail to load, ensuring exercises remain functional

---

## Scenario-Based Practice Mode (Planned - V2.0)

### Architecture Overview

**Status:** üéØ Designed - Ready for Implementation

The Practice Mode (replacing "Practise (AI)") implements a **Game State Architecture** rather than a simple chatbot, solving the "blank page problem" where learners don't know what to say to an open-ended AI tutor.

### Core Design Principles

1. **Scenario-Based Learning:** Users engage in realistic, contextual conversations (e.g., "Ordering Coffee at a Caf√©", "Buying a Train Ticket") rather than free-form chat
2. **Mode Separation:** Strict separation between **Voice Mode** (üéôÔ∏è) and **Text Mode** (üí¨) to prevent cognitive interference (Redundancy Effect)
3. **Game Loop Architecture:** Structured conversation flow with clear win conditions and feedback phases

### Technical Implementation

#### 1. Stage Manager Pattern (Topic Control)

**Problem:** LLMs naturally drift off-topic during roleplay conversations.

**Solution:** Structured System Prompt that acts as a "Stage Manager" defining:
- **Current Scene:** Context and setting
- **Winning Condition:** Goal that ends the interaction
- **Constraints:** Response length, topic boundaries

**Example System Prompt:**
```
"You are roleplaying as a Barista in a busy Italian caf√©.
Current Scene: The user is a customer ordering a cappuccino and a cornetto.
Your Goal: Take their order, ask if they want it 'al banco' (at the bar) or 'al tavolo' (at the table), and calculate the total price.
Constraints: Keep responses short (under 20 words). If the user changes the topic (e.g., asks about the weather), politely bring them back to the order."
```

**Drift Prevention:** Backend appends invisible reminder to prompt history before LLM call:
```
[System Note: focus on the coffee order; do not discuss unrelated topics.]
```

#### 2. Goal Check Classifier (Ending Detection)

**Problem:** LLMs never naturally "stop" talking - conversations can continue indefinitely.

**Solution:** "Hidden Thought" Method - Request structured JSON output from Llama 3 Instruct containing both internal state and external speech.

**JSON Response Format:**
```json
{
  "thought": "The user has successfully ordered and paid. The interaction is complete.",
  "scene_status": "COMPLETE",
  "reply": "Ecco a lei. Buona giornata!"
}
```

**Backend Logic:**
- Parse JSON response
- If `scene_status == "COMPLETE"`: Display success modal, end voice recording, trigger feedback phase
- If `scene_status == "ACTIVE"`: Continue conversation loop

#### 3. Post-Game Report (Feedback System)

**Design Philosophy:** No real-time corrections during roleplay (breaks immersion). Feedback provided after conversation completes, like a video game "Mission Report."

**Feedback Architecture:**

**Pronunciation Analysis:**
- Uses Whisper STT confidence scores from client-side
- Levenshtein distance metric for phonetic scoring
- Flags low-confidence transcriptions (e.g., "connetto" instead of "cornetto")

**Grammar & Vocabulary Review:**
- Entire conversation transcript sent to Llama 3 with review prompt:
  ```
  "Review this transcript. Find 3 grammatical errors and suggest 2 better vocabulary words for a beginner learner."
  ```
- Separate system prompt for feedback generation (different from roleplay prompt)

**Contextual Vocabulary Introduction:**
- Scenario-specific vocabulary priming via prompt injection
- Example: "Buying a Train Ticket" scenario ensures words like "binario" (platform) and "biglietto" (ticket) appear naturally
- LLM can explain vocabulary within context when user asks, improving retention vs. flashcards

#### 4. Voice Mode vs. Text Mode Separation

**Cognitive Science Rationale:** Mixing reading/typing with listening/speaking triggers "Redundancy Effect" - learners default to reading when text is visible, stopping active listening practice.

**UI Implementation:**
- **Toggle Switch:** `[ üéôÔ∏è Voice Mode ] ‚Üî [ üí¨ Text Mode ]` at top of Practice screen
- **Mode Isolation:** Each mode has distinct interface and backend endpoints

**Technical Architecture:**

**Voice Mode Endpoint** (`/api/voice-chat`):
- **Input:** Audio file (MediaRecorder API)
- **Process:** Whisper STT ‚Üí Llama 3 (with Game State) ‚Üí XTTS-v2 TTS
- **Output:** Audio file
- **GPU Operations:** STT + LLM + TTS (expensive, isolated)

**Text Mode Endpoint** (`/api/text-chat`):
- **Input:** Text string
- **Process:** Llama 3 only (with Game State)
- **Output:** Text string
- **GPU Operations:** LLM only (cheap, fast)

**Transcript Bridge:**
- When Voice Mode conversation completes, transcript automatically saved
- User switches to Text Mode ‚Üí System message: "Here is the transcript of your voice conversation. Review your mistakes below."
- Enables review without breaking mode separation

### Game Loop Flow

```
1. User Speaks ‚Üí Whisper STT (transcription)
2. Backend Analysis ‚Üí Check if "Winning Condition" met (via JSON scene_status)
3. Response Generation:
   - If COMPLETE: Generate closing line + Generate "Mission Report" (Feedback)
   - If ACTIVE: Generate Character Response
4. Audio Playback ‚Üí XTTS-v2 TTS (Voice Mode) or Text Display (Text Mode)
5. Loop continues until scene_status == "COMPLETE"
6. Post-Game Report displayed with pronunciation, grammar, and vocabulary feedback
```

### Push-to-Talk Implementation

**Component:** `PushToTalkButton` (React)
- **Hold-to-Record:** MediaRecorder API (existing implementation)
- **Visual Feedback:** Button state changes during recording
- **Release-to-Send:** Audio sent to `/api/voice-chat` endpoint
- **Walkie-Talkie UX:** One-way communication prevents interruption

---

## Roadmap: Next Steps (Priority)

1. **Scenario-Based Practice Mode Implementation (Priority):**
    
    - Implement Game State Architecture in FastAPI backend
        
    - Create Stage Manager Pattern system prompts
        
    - Implement Goal Check Classifier with JSON response parsing
        
    - Build Post-Game Report feedback system
        
    - Develop Voice/Text Mode toggle UI
        
    - Create PushToTalkButton component
        
    - Design scenario library (e.g., "Ordering Coffee", "Buying Train Ticket")
        
2. **Voice Integration Enhancement:**
    
    - Migrate from Edge-TTS to **XTTS-v2** for AI Audio Output (TTS) with voice cloning capability.
        
    - Implement GPU Load Management strategy (Model Ducking/Quantization) in the FastAPI backend.
        
3. **Module A1.2 Implementation:** Begin development of "Personal Information & Family" module following the same exercise structure and learning loop.
    
4. **Core Curriculum Review:** Ensure all **10-Module A1 Course** content is pedagogically correct and complete before migration.
    
5. **Cloud Migration ("The Hub"):**
    
    - **Backend:** Deploy Dockerized FastAPI to **RunPod Serverless GPU**.
        
    - **Database:** Migrate local MongoDB to **MongoDB Atlas (Free Tier)**.
        
    - **Frontend:** Deploy React app to **Vercel/Netlify**.
        
6. **Mobile App Conversion:** Package the React frontend into a native container using **Capacitor**.
    
    - Use `npx cap add android` and `npx cap add ios` to create native projects pointing to the cloud backend (The Hub).
        
7. **Code Cleanup:** Resolve Pydantic V2 and FastAPI `lifespan` deprecation warnings identified during testing.

---

## Technical Notes

### Practice Mode Architecture

- **Game State Management:** Conversation state tracked in backend with scene_status, win conditions, and conversation history
- **System Prompt Templates:** Structured prompts for Stage Manager Pattern stored in backend configuration
- **JSON Response Parsing:** Llama 3 Instruct configured to return structured JSON for scene_status detection
- **Feedback Generation:** Separate LLM calls with review-focused prompts for Post-Game Report generation
- **Mode Separation:** Frontend state management ensures Voice and Text modes never mix in UI

### Data Structure

- **Module Data:** Structured in `backend/a1_1_module_data.py` with hierarchical lesson/exercise organization
- **Exercise Validation:** Context-aware validation logic in `frontend/src/App.jsx` with fallback mechanisms
- **Boss Fight:** Static conversation flow with hard-coded messages and validation rules
- **New Exercise Fields:** 
  - `audio_text`: Hidden sentence for listening comprehension (read by TTS, not displayed)
  - `common_mistakes`: Array of pattern-based mistake detection with explanations
  - `review`: Boolean flag for vocabulary review exercises
  - `extension`: Boolean flag for optional extension activities
  - `cultural_note`: Boolean flag for cultural information cards
  - `required_elements`: Array for free writing validation
  - `form_fields`: Array of field definitions for form fill exercises

### Key Files

- `frontend/src/App.jsx` - Main React application with all exercise components
- `frontend/src/components/PushToTalkButton.jsx` - Voice Mode recording component (to be created)
- `backend/server.py` - FastAPI backend with lesson endpoints and voice processing
- `backend/practice_mode.py` - Scenario-based practice mode logic (to be created)
- `backend/scenario_templates.py` - System prompt templates for scenarios (to be created)
- `backend/a1_1_module_data.py` - Module A1.1 structured data
- `context-docs/course-docs/The PolyBot A1 Curriculum Master Reference.md` - Curriculum reference

